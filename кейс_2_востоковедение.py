# -*- coding: utf-8 -*-
"""Кейс 2 Востоковедение.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17gZA3eeRlV2nqassjDIDQFtW3vN3ZWSS
"""

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

import gzip
import shutil

# Path to the compressed .gz file
gz_file_path = '/content/drive/MyDrive/Colab Notebooks/www.hk01.com-2022-05.warc.gz'
# Path to the decompressed .warc file
warc_file_path = '/content/drive/MyDrive/Colab Notebooks/www.hk01.com-2022-05.warc'

# Decompress the .gz file
with gzip.open(gz_file_path, 'rb') as f_in:
    with open(warc_file_path, 'wb') as f_out:
        shutil.copyfileobj(f_in, f_out)

!pip install warcio

from warcio.archiveiterator import ArchiveIterator

# Функция для извлечения текстового содержимого из WARC записей
def extract_text_from_warc(file_path):
    with open(file_path, 'rb') as stream:
        for record in ArchiveIterator(stream):
            if record.rec_type == 'response':
                payload = record.content_stream().read()
                # Предполагая, что содержимое является HTML, вы можете его распарсить, чтобы извлечь текст
                # Для простоты, мы просто декодируем и печатаем содержимое
                print(payload.decode('utf-8', errors='ignore'))

# Путь к распакованному файлу .warc
warc_file_path = '/content/drive/MyDrive/Colab Notebooks/www.hk01.com-2022-05.warc'

# Извлечение и печать текстового содержимого
extract_text_from_warc(warc_file_path)

from warcio.archiveiterator import ArchiveIterator
from bs4 import BeautifulSoup

# Функция для извлечения текстового содержимого из WARC записей и записи его в файл
def extract_text_from_warc(file_path, output_file_path):
    with open(file_path, 'rb') as stream, open(output_file_path, 'w', encoding='utf-8') as output_file:
        for record in ArchiveIterator(stream):
            if record.rec_type == 'response':
                payload = record.content_stream().read()
                soup = BeautifulSoup(payload, 'html.parser')
                # Извлечение текстового содержимого из HTML
                text = soup.get_text()
                output_file.write(text + '\n\n')

# Путь к распакованному файлу .warc
warc_file_path = '/content/drive/MyDrive/Colab Notebooks/www.hk01.com-2022-05.warc'
# Путь к файлу для записи данных
output_file_path = '/content/drive/MyDrive/Colab Notebooks/output_text.txt'

# Извлечение и запись текстового содержимого
extract_text_from_warc(warc_file_path, output_file_path)

output_file_path = '/content/drive/MyDrive/Colab Notebooks/output_text.txt'

# Чтение и вывод содержимого текстового файла
with open(output_file_path, 'r', encoding='utf-8') as file:
    content = file.read()
    print(content)

output_file_path = '/content/drive/MyDrive/Colab Notebooks/output_text.txt'

# Чтение и вывод первых 10 строк текстового файла
with open(output_file_path, 'r', encoding='utf-8') as file:
    for i, line in enumerate(file):
        if i >= 10000:
            break
        print(line.strip())

!jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000

from warcio.archiveiterator import ArchiveIterator
from bs4 import BeautifulSoup

# Функция для извлечения текстового содержимого из WARC записей и вывода его в консоль
def extract_text_from_warc(file_path):
    with open(file_path, 'rb') as stream:
        for record in ArchiveIterator(stream):
            if record.rec_type == 'response':
                payload = record.content_stream().read()
                soup = BeautifulSoup(payload, 'html.parser')
                # Извлечение и печать текстового содержимого из HTML
                text = soup.get_text()
                print(text)

# Путь к распакованному файлу .warc
warc_file_path = '/content/drive/MyDrive/Colab Notebooks/www.hk01.com-2022-05.warc'

# Извлечение и печать текстового содержимого
extract_text_from_warc(warc_file_path)

from warcio.archiveiterator import ArchiveIterator
from bs4 import BeautifulSoup

# Функция для извлечения и вывода ограниченного количества записей из WARC файла
def extract_limited_text_from_warc(file_path, limit=10):
    count = 0
    with open(file_path, 'rb') as stream:
        for record in ArchiveIterator(stream):
            if record.rec_type == 'response':
                payload = record.content_stream().read()
                soup = BeautifulSoup(payload, 'html.parser')
                text = soup.get_text()
                print(text)
                count += 1
                if count >= limit:
                    break

# Путь к распакованному файлу .warc
warc_file_path = '/content/drive/MyDrive/Colab Notebooks/www.hk01.com-2022-05.warc'

# Извлечение и вывод первых 10 записей
extract_limited_text_from_warc(warc_file_path, limit=10)

from warcio.archiveiterator import ArchiveIterator
from bs4 import BeautifulSoup

# Функция для извлечения заголовка и основного текста из WARC записей
def extract_title_and_text_from_warc(file_path, limit=10):
    count = 0
    with open(file_path, 'rb') as stream:
        for record in ArchiveIterator(stream):
            if record.rec_type == 'response':
                payload = record.content_stream().read()
                soup = BeautifulSoup(payload, 'html.parser')

                # Извлечение заголовка
                title = soup.title.string if soup.title else 'No title'

                # Извлечение основного текста
                paragraphs = soup.find_all('p')
                text = '\n'.join([p.get_text() for p in paragraphs])

                print(f"Title: {title}\n")
                print(f"Text: {text}\n")
                print("="*80)

                count += 1
                if count >= limit:
                    break

# Путь к распакованному файлу .warc
warc_file_path = '/content/drive/MyDrive/Colab Notebooks/www.hk01.com-2022-05.warc'

# Извлечение и вывод заголовков и текста первых 10 записей
extract_title_and_text_from_warc(warc_file_path, limit=10)

!pip install spacy transformers
!python -m spacy download zh_core_web_trf
!python -m spacy download ru_core_news_lg

import spacy
from transformers import MarianMTModel, MarianTokenizer

# Загрузка модели NER для китайского языка
nlp_zh = spacy.load("zh_core_web_trf")

# Загрузка модели перевода с китайского на русский

# Функция для обнаружения имен собственных
def detect_proper_nouns(text):
    doc = nlp_zh(text)
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    return entities

# Функция для замены имен собственных на теги
def tag_proper_nouns(text, entities):
    for ent, label in entities:
        if label in ['PERSON', 'ORG', 'GPE']:  # Можно добавить другие категории, если нужно
            text = text.replace(ent, f"<PROPN>{ent}</PROPN>")
    return text

# Пример китайского текста
chinese_text = "小米公司宣布了新产品。"

# Обнаружение и тегирование имен собственных
entities = detect_proper_nouns(chinese_text)
tagged_text = tag_proper_nouns(chinese_text, entities)

tagged_text

!export YANDEX_API_KEY=AQVNxDjsG_WBJvlAVaBFe8Fv2agI-O4GhF39G9GA

import os
os.environ['YANDEX_API_KEY'] = 'AQVNxDjsG_WBJvlAVaBFe8Fv2agI-O4GhF39G9GA'

text = "小米公司宣布了新产品。"

import requests
import os

def call_api(url, data):
    api_key = os.environ.get('YANDEX_API_KEY')  # Получение API ключа из переменной окружения
    if not api_key:
        raise ValueError("API key not found in environment variables.")

    headers = { "Authorization" : f"Api-Key {api_key}" }
    response = requests.post(url, json=data, headers=headers)
    response.raise_for_status()  # Проверка на успешность запроса
    return response.json()

# Пример китайского текста
text = "小米公司宣布了新产品。"

# Вызов API Яндекс.Переводчика для перевода текста
translated_response = call_api("https://translate.api.cloud.yandex.net/translate/v2/translate", {
  "targetLanguageCode": "ru",
  "texts": [text]
})

# Получение переведенного текста
translated_text = translated_response['translations'][0]['text']
print("Переведенный текст:", translated_text)

import requests
import spacy
import os

# Загрузка модели NER для китайского языка
nlp_zh = spacy.load("zh_core_web_trf")

# Загрузка модели для русского языка
nlp_ru = spacy.load("ru_core_news_lg")

# Функция для обнаружения имен собственных
def detect_proper_nouns(text):
    doc = nlp_zh(text)
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    return entities

# Функция для замены имен собственных на уникальные маркеры
def replace_proper_nouns(text, entities):
    replacements = {}
    for i, (ent, label) in enumerate(entities):
        if label in ['PERSON', 'ORG', 'GPE']:  # Можно добавить другие категории, если нужно
            marker = f"PROPN_{i}"
            replacements[marker] = ent
            text = text.replace(ent, marker)
    return text, replacements

# Функция для восстановления имен собственных из маркеров
def restore_proper_nouns(text, replacements):
    for marker, ent in replacements.items():
        text = text.replace(marker, ent)
    return text

# Функция для перевода текста с использованием API Яндекс.Переводчика
def translate_text_yandex(api_key, text, lang_from, lang_to):
    url = "https://translate.api.cloud.yandex.net/translate/v2/translate"
    params = {
        "targetLanguageCode": lang_to,
        "texts": [text]
    }
    headers = {"Authorization": f"Api-Key {api_key}"}
    response = requests.post(url, json=params, headers=headers)
    response.raise_for_status()  # Проверка на успешность запроса
    result = response.json()
    return result["translations"][0]["text"]

# Пример китайского текста
chinese_text = "市选举大胜 不足以反映泰国大选风向 早报 印尼传教士被拒入境 支持者恫言向新加坡发动类似911恐袭 马国下月起暂停出口活鸡 本地价格及供应将受冲击 关于猴痘病毒"

# Ваш API ключ Яндекс.Переводчика (можно установить вручную или через переменные окружения)
yandex_api_key = os.environ.get('YANDEX_API_KEY')
if not yandex_api_key:
    yandex_api_key = 'YOUR_YANDEX_API_KEY'

# Обнаружение и замена имен собственных
entities = detect_proper_nouns(chinese_text)
tagged_text, replacements = replace_proper_nouns(chinese_text, entities)

# Перевод текста с тегами
translated_text = translate_text_yandex(yandex_api_key, tagged_text, "zh", "ru")

# Восстановление имен собственных
translated_text = restore_proper_nouns(translated_text, replacements)

print("Переведенный текст:", translated_text)

# Анализ переведенного текста с использованием модели spaCy для русского языка
doc_ru = nlp_ru(translated_text)
for sent in doc_ru.sents:
    print(sent.text)

!pip install clickhouse-connect

import clickhouse_connect
from datetime import datetime
import uuid
import os

global client  # pylint:  disable=global-statement
client = clickhouse_connect.get_client(
    host='ie8703b22o.eu-central-1.aws.clickhouse.cloud',
    user='default',
    password='_QG1JpW57iXEC',
    secure=True
)

def get_all_tables(client):
    query = "SELECT name FROM system.tables WHERE database = currentDatabase()"
    result = client.query(query)
    tables = result.result_rows
    return [table[0] for table in tables]

# Функция для получения всех колонок для заданной таблицы
def get_columns_for_table(client, table_name):
    query = f"SELECT name, type FROM system.columns WHERE database = currentDatabase() AND table = '{table_name}'"
    result = client.query(query)
    columns = result.result_rows
    return columns

# Получение и вывод всех таблиц и их колонок
def display_tables_and_columns(client):
    tables = get_all_tables(client)
    for table in tables:
        print(f"Таблица: {table}")
        columns = get_columns_for_table(client, table)
        for column in columns:
            print(f"  Колонка: {column[0]}, Тип: {column[1]}")
        print()

# Запуск функции для отображения таблиц и колонок
display_tables_and_columns(client)

import pandas as pd

query = """
SELECT data_id, marked_data, date, language, link
FROM raw_data
LIMIT 100
"""

# Execute the query and fetch the data
data = client.query(query).result_rows

# Define the column names
columns = ['data_id', 'marked_data', 'date', 'language', 'link']

# Convert the data into a pandas DataFrame
df = pd.DataFrame(data, columns=columns)

# Display the DataFrame
print(df)

query = """
SELECT data_id, marked_data, character_length(marked_data)
FROM parsed_data
"""

# Execute the query and fetch the data
data = client.query(query).result_rows

columns = ['data_id', 'marked_data', 'count']

# Convert the data into a pandas DataFrame
df = pd.DataFrame(data, columns=columns)

# Display the DataFrame
df

df['count'].sum()

!pip install spacy transformers
!python -m spacy download ja_core_news_md
!python -m spacy download ru_core_news_lg

import requests
import spacy
import os

# Загрузка модели NER для японского языка
nlp_zh = spacy.load("ja_core_news_md")

# Загрузка модели для русского языка
nlp_ru = spacy.load("ru_core_news_lg")

# Функция для обнаружения имен собственных
def detect_proper_nouns(text):
    doc = nlp_zh(text)
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    return entities

# Функция для замены имен собственных на уникальные маркеры
def replace_proper_nouns(text, entities):
    replacements = {}
    for i, (ent, label) in enumerate(entities):
        if label in ['PERSON', 'ORG', 'GPE']:  # Можно добавить другие категории, если нужно
            marker = f"PROPN_{i}"
            replacements[marker] = ent
            text = text.replace(ent, marker)
    return text, replacements

# Функция для восстановления имен собственных из маркеров
def restore_proper_nouns(text, replacements):
    for marker, ent in replacements.items():
        text = text.replace(marker, ent)
    return text

# Функция для перевода текста с использованием API Яндекс.Переводчика
def translate_text_yandex(api_key, text, lang_from, lang_to):
    url = "https://translate.api.cloud.yandex.net/translate/v2/translate"
    params = {
        "targetLanguageCode": lang_to,
        "texts": [text]
    }
    headers = {"Authorization": f"Api-Key {api_key}"}
    response = requests.post(url, json=params, headers=headers)
    response.raise_for_status()  # Проверка на успешность запроса
    result = response.json()
    return result["translations"][0]["text"]

# Пример китайского текста
chinese_text = "ソニー株式会社は新製品を発表しました。"

# Ваш API ключ Яндекс.Переводчика (можно установить вручную или через переменные окружения)
yandex_api_key = os.environ.get('YANDEX_API_KEY')
if not yandex_api_key:
    yandex_api_key = 'YOUR_YANDEX_API_KEY'

# Обнаружение и замена имен собственных
entities = detect_proper_nouns(chinese_text)
tagged_text, replacements = replace_proper_nouns(chinese_text, entities)

# Перевод текста с тегами
translated_text = translate_text_yandex(yandex_api_key, tagged_text, "zh", "ru")

# Восстановление имен собственных
translated_text = restore_proper_nouns(translated_text, replacements)

print("Переведенный текст:", translated_text)

# Анализ переведенного текста с использованием модели spaCy для русского языка
doc_ru = nlp_ru(translated_text)
for sent in doc_ru.sents:
    print(sent.text)